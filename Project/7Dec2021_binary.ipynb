{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78495a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "377c3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"train-65-binary.csv\")\n",
    "#df = df.dropna()\n",
    "rows = df.shape[0]\n",
    "print(rows)\n",
    "groups = np.array(np.zeros(rows))\n",
    "for i in range(0, int(rows/100)):\n",
    "    for j in range(0, 99):\n",
    "        groups[j] = int(i)\n",
    "        #print(groups[j])\n",
    "#print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a4c1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98] TEST: [  99  100  101 ... 6497 6498 6499]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98] [  99  100  101 ... 6497 6498 6499]\n",
      "TRAIN: [  99  100  101 ... 6497 6498 6499] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98]\n",
      "[  99  100  101 ... 6497 6498 6499] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98]\n"
     ]
    }
   ],
   "source": [
    "#LOGO\n",
    "logo = LeaveOneGroupOut()\n",
    "X = df.iloc[:, 3:43]\n",
    "y = df.iloc[:, 2]\n",
    "logo.get_n_splits(X, y, groups)\n",
    "logo.get_n_splits(groups=groups)\n",
    "for train_index, test_index in logo.split(X, y, groups=groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"%s %s\" % (train_index, test_index))\n",
    "    #print(\"X_train:\", X_train, \"X_test:\", X_test, \"y_train:\", y_train, \"y_test:\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e185625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the rows of the dataframe\n",
    "#df = shuffle(df)\n",
    "#splitting the data into training and validation sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "197fa10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 81.82%\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST\n",
    "#train\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "y_pred = model.predict(X_test)\n",
    "#print(y_pred)\n",
    "predictions = [value for value in y_pred]\n",
    "#print(predictions)\n",
    "#perform some metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "#validate\n",
    "\n",
    "\n",
    "#test on unseen data\n",
    "df_test = pd.read_csv(r\"Biovid_Test_15_Subjects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20ed6ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meg/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "SVC_y_pred = LinearSVC(random_state=0).fit(X_test, y_test).predict(X_test)\n",
    "#print(SVC_y_pred)\n",
    "accuracy = accuracy_score(y_test, SVC_y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
